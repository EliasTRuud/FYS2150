{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ab042",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyaudio\n",
    "%pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285bbb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "\n",
    "def pyaudio_acquisition(RECORD_SECONDS,RATE):\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    CHUNK = 1024\n",
    "    audio = pyaudio.PyAudio()\n",
    "     \n",
    "    # start Recording\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "    print (\"recording...\")\n",
    "    #frames = []\n",
    "     \n",
    "    \n",
    "    buffer = stream.read(RATE * RECORD_SECONDS)\n",
    "    mydata = np.frombuffer(buffer,dtype = \"int16\")\n",
    "    \n",
    "    \n",
    "    #for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "     #   data = stream.read(CHUNK)\n",
    "      #  frames.append(np.fromstring(data, dtype=float))\n",
    "        #frames.extend(np.frombuffer(data, dtype = float))\n",
    "    print (\"finished recording\")\n",
    "    \n",
    "    \n",
    "    #mydata = np.hstack(frames)\n",
    "    #mydata = np.hstack(frames)\n",
    "    \n",
    "     \n",
    "    # stop Recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "    save = input(\"Vil du lagre dataene som en .wav fil [Y/n]?  \")\n",
    "    if save == \"Y\" or save == \"y\":\n",
    "       WAVE_OUTPUT_FILENAME = input(\"Skriv filnavn på formen filename.wav \")   \n",
    "       waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "       waveFile.setnchannels(CHANNELS)\n",
    "       waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "       waveFile.setframerate(RATE)\n",
    "       waveFile.writeframes(b''.join(mydata))\n",
    "       waveFile.close()\n",
    "\n",
    "    return mydata\n",
    "\n",
    "\n",
    "#pyaudio_acquisition(5, 44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f82c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyaudio\n",
    "import wave\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "#from sound_acquisition_pyaudio import pyaudio_acquisition\n",
    "import os\n",
    "import requests\n",
    "\n",
    "#Ta opp lyd-data for å finne egenfrekvensen til messingsstaven\n",
    "#Jacob Lie 22.4.21, basert på matlab kode fra Alex Read 1.3.18\n",
    "\n",
    "\n",
    "fmin = 5e2 #minimumsfrekvens for å fjerne støy\n",
    "fmax = 2e3\n",
    "\n",
    "\n",
    "fmin = 500  #definerer en minimumsfrekvens for å fjerne støy\n",
    "fmax = 2000\n",
    "\n",
    "duration = 10 #default opptakstid\n",
    "samplerate = 15000 #default samplerate\n",
    "\n",
    "\n",
    "\n",
    "RR = \"n\"\n",
    "\n",
    "#Om du har kjørt dette programmet før, kommenter vekk linjen under.\n",
    "RR = input(\"Er dette første gang du kjører FFTlyd? [Y/n] \")\n",
    "\n",
    "if RR == \"Y\" or RR == \"y\":\n",
    "    if \"RANGGYU.wav\" not in os.listdir(os.getcwd()):\n",
    "        url = \"https://github.com/jacobllie/RANGGYU/blob/main/RANGGYU.wav?raw=true\"\n",
    "        raw = requests.get(url).content\n",
    "\n",
    "        with open('RANGGYU.wav', mode='bx') as f:\n",
    "            f.write(raw)\n",
    "\n",
    "\n",
    "    # Set chunk size of 1024 samples per data frame\n",
    "    chunk = 1024\n",
    "\n",
    "    # Open the sound file\n",
    "    wf = wave.open(\"RANGGYU.wav\", 'rb')\n",
    "\n",
    "    # Create an interface to PortAudio\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # Open a .Stream object to write the WAV file to\n",
    "    # 'output = True' indicates that the sound will be played rather than recorded\n",
    "    stream = p.open(format = p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels = wf.getnchannels(),\n",
    "                    rate = wf.getframerate(),\n",
    "                    output = True)\n",
    "\n",
    "    # Read data in chunks\n",
    "    data = wf.readframes(chunk)\n",
    "\n",
    "    # Play the sound by writing the audio data to the stream\n",
    "    while data != '':\n",
    "        stream.write(data)\n",
    "        data = wf.readframes(chunk)\n",
    "\n",
    "    # Close and terminate the stream\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "inputs = input(\"Har du en lydfil fra før? [Y/n] \")\n",
    "\n",
    "if inputs == \"Y\" or inputs == \"y\":\n",
    "    filename = input(\"Skriv inn filnavn på formen filnavn.wav \")\n",
    "    mydata, samplerate = sf.read(filename)\n",
    "\n",
    "if inputs == \"N\" or inputs == \"n\":\n",
    "    #temp = input(\"Skriv inn samplerate og duration \").split()\n",
    "    #samplerate = int(temp[0])\n",
    "    #duration = int(temp[1])\n",
    "\n",
    "    mydata = pyaudio_acquisition(duration, samplerate)\n",
    "\n",
    "    \"\"\"For sounddevice unhash linjen under.\"\"\"\n",
    "    #mydata = sound_data_acquisition(duration, samplerate).transpose().reshape(-1)\n",
    "    \"\"\"\n",
    "    Dersom du bruker sounddevice så vil mydata har shapen (1,n),\n",
    "    for at fourier transformasjonen skal gå riktig for seg,\n",
    "    er vi nødt til å først transponere den til (n,1), deretter reshape\n",
    "    den slik at den får formen (n,).\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "try:\n",
    "    print(\"{} antall samples er registrert.\" .format(len(mydata)))\n",
    "except:\n",
    "    print(\"\\n Har du husket å unhashe mydata linjen i linje 78?\")\n",
    "\n",
    "\n",
    "t = np.linspace(0,len(mydata)//samplerate,len(mydata))\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "plt.subplot(121)\n",
    "plt.xlabel(\"Tid [s]\")\n",
    "plt.ylabel(\"Amplitude [a.u]\")\n",
    "plt.plot(t,mydata)\n",
    "\n",
    "Y = np.fft.fft(mydata)\n",
    "power = np.abs(Y[:len(Y)//2]) #ønsker bare de reelle verdiene, og vil ikke\n",
    "#inkludere speilingen, derfor har vi len(Y)//2\n",
    "\n",
    "\n",
    "FFT_freq = samplerate//2*np.linspace(0,1,len(power))  #Deler på to pga. Nyquistfrekvensen\n",
    "\n",
    "\n",
    "fmin_index = np.where(FFT_freq >= fmin)\n",
    "fmax_index = np.where(FFT_freq <= fmax)\n",
    "FFT_freq = FFT_freq[np.min(fmin_index):np.max(fmax_index)] #fjerner støy og justerer x-aksen\n",
    "\n",
    "power = power[np.min(fmin_index):np.max(fmax_index)]\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.xlabel(\"Frekvens [Hz]\")\n",
    "plt.ylabel(\"Amplitude [a.u.]\")\n",
    "plt.plot(FFT_freq,power)\n",
    "plt.show()\n",
    "\n",
    "#Finner egenfrekvensen til staven.\n",
    "\n",
    "print(\"Grunntonen er {:.4} Hz\".format(FFT_freq[np.argmax(power)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cf1e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed43ec6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
